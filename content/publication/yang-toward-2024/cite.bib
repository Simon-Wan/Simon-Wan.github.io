@misc{yang_toward_2024,
 abstract = {Optical music recognition (OMR) aims to convert music notation into digital formats. One approach to tackle OMR is through a multi-stage pipeline, where the system first detects visual music notation elements in the image (object detection) and then assembles them into a music notation (notation assembly). Most previous work on notation assembly unrealistically assumes perfect object detection. In this study, we focus on the MUSCIMA++ v2.0 dataset, which represents musical notation as a graph with pairwise relationships among detected music objects, and we consider both stages together. First, we introduce a music object detector based on YOLOv8, which improves detection performance. Second, we introduce a supervised training pipeline that completes the notation assembly stage based on detection output. We find that this model is able to outperform existing models trained on perfect detection output, showing the benefit of considering the detection and assembly stages in a more holistic way. These findings, together with our novel evaluation metric, are important steps toward a more complete OMR solution.},
 author = {Yang, Guang and Zhang, Muru and Qiu, Lin and Wan, Yanming and Smith, Noah A.},
 file = {Preprint PDF:/Users/Roy/Zotero/storage/CSISSZB2/Yang ç­‰ - 2024 - Toward a More Complete OMR Solution.pdf:application/pdf;Snapshot:/Users/Roy/Zotero/storage/AK9GI9UA/2409.html:text/html},
 keywords = {Computer Science - Artificial Intelligence, Computer Science - Computer Vision and Pattern Recognition},
 month = {August},
 note = {arXiv:2409.00316},
 publisher = {arXiv},
 title = {Toward a More Complete OMR Solution},
 url = {http://arxiv.org/abs/2409.00316},
 urldate = {2024-10-27},
 year = {2024}
}
